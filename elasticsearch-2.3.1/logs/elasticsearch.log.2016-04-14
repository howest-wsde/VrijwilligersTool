[2016-04-14 14:40:51,782][INFO ][node                     ] [Annalee] version[2.3.1], pid[8164], build[bd98092/2016-04-04T12:25:05Z]
[2016-04-14 14:40:51,783][INFO ][node                     ] [Annalee] initializing ...
[2016-04-14 14:40:53,010][INFO ][plugins                  ] [Annalee] modules [lang-groovy, reindex, lang-expression], plugins [], sites []
[2016-04-14 14:40:53,124][INFO ][env                      ] [Annalee] using [1] data paths, mounts [[/home/vagrant/Code (home_vagrant_Code)]], net usable_space [32.2gb], net total_space [221.5gb], spins? [possibly], types [vboxsf]
[2016-04-14 14:40:53,124][INFO ][env                      ] [Annalee] heap size [1015.6mb], compressed ordinary object pointers [true]
[2016-04-14 14:40:53,125][WARN ][env                      ] [Annalee] max file descriptors [4096] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-04-14 14:40:55,949][INFO ][node                     ] [Annalee] initialized
[2016-04-14 14:40:55,949][INFO ][node                     ] [Annalee] starting ...
[2016-04-14 14:40:56,030][INFO ][transport                ] [Annalee] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-04-14 14:40:56,037][INFO ][discovery                ] [Annalee] elasticsearch/74582LLmRMWrlZM2RRIR0g
[2016-04-14 14:40:59,140][INFO ][cluster.service          ] [Annalee] new_master {Annalee}{74582LLmRMWrlZM2RRIR0g}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-04-14 14:40:59,153][INFO ][http                     ] [Annalee] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-04-14 14:40:59,155][INFO ][node                     ] [Annalee] started
[2016-04-14 14:40:59,232][INFO ][gateway                  ] [Annalee] recovered [0] indices into cluster_state
[2016-04-14 14:41:29,160][INFO ][cluster.routing.allocation.decider] [Annalee] low disk watermark [85%] exceeded on [74582LLmRMWrlZM2RRIR0g][Annalee][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/0] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:41:59,167][INFO ][cluster.routing.allocation.decider] [Annalee] low disk watermark [85%] exceeded on [74582LLmRMWrlZM2RRIR0g][Annalee][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/0] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:43:08,064][INFO ][node                     ] [Tower] version[2.3.1], pid[8218], build[bd98092/2016-04-04T12:25:05Z]
[2016-04-14 14:43:08,065][INFO ][node                     ] [Tower] initializing ...
[2016-04-14 14:43:09,239][INFO ][plugins                  ] [Tower] modules [lang-groovy, reindex, lang-expression], plugins [], sites []
[2016-04-14 14:43:09,367][INFO ][env                      ] [Tower] using [1] data paths, mounts [[/home/vagrant/Code (home_vagrant_Code)]], net usable_space [32.1gb], net total_space [221.5gb], spins? [possibly], types [vboxsf]
[2016-04-14 14:43:09,368][INFO ][env                      ] [Tower] heap size [1015.6mb], compressed ordinary object pointers [true]
[2016-04-14 14:43:09,369][WARN ][env                      ] [Tower] max file descriptors [4096] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-04-14 14:43:12,187][INFO ][node                     ] [Tower] initialized
[2016-04-14 14:43:12,188][INFO ][node                     ] [Tower] starting ...
[2016-04-14 14:43:12,274][INFO ][transport                ] [Tower] publish_address {127.0.0.1:9301}, bound_addresses {127.0.0.1:9301}, {[::1]:9301}
[2016-04-14 14:43:12,281][INFO ][discovery                ] [Tower] elasticsearch/WBVIxgdISN27I0RKU9yuBQ
[2016-04-14 14:43:16,107][WARN ][discovery.zen.ping.unicast] [Tower] failed to send ping to [{#zen_unicast_6#}{::1}{[::1]:9300}]
ReceiveTimeoutTransportException[[][[::1]:9300][internal:discovery/zen/unicast] request_id [4] timed out after [3751ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:679)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-04-14 14:43:16,108][WARN ][discovery.zen.ping.unicast] [Tower] failed to send ping to [{#zen_unicast_1#}{127.0.0.1}{127.0.0.1:9300}]
ReceiveTimeoutTransportException[[][127.0.0.1:9300][internal:discovery/zen/unicast] request_id [2] timed out after [3751ms]]
	at org.elasticsearch.transport.TransportService$TimeoutHandler.run(TransportService.java:679)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
[2016-04-14 14:43:16,910][INFO ][cluster.service          ] [Tower] new_master {Tower}{WBVIxgdISN27I0RKU9yuBQ}{127.0.0.1}{127.0.0.1:9301}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-04-14 14:43:16,933][INFO ][http                     ] [Tower] publish_address {127.0.0.1:9201}, bound_addresses {127.0.0.1:9201}, {[::1]:9201}
[2016-04-14 14:43:16,934][INFO ][node                     ] [Tower] started
[2016-04-14 14:43:17,026][INFO ][gateway                  ] [Tower] recovered [0] indices into cluster_state
[2016-04-14 14:43:46,933][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:44:16,936][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:44:46,939][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:45:16,942][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:45:46,945][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:46:16,949][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:46:46,952][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:47:16,955][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.1gb[14.5%], replicas will not be assigned to this node
[2016-04-14 14:47:46,960][INFO ][cluster.routing.allocation.decider] [Tower] low disk watermark [85%] exceeded on [WBVIxgdISN27I0RKU9yuBQ][Tower][/home/vagrant/Code/RoeselareVrijwilligt/VrijwilligersTool/elasticsearch-2.3.1/data/elasticsearch/nodes/1] free: 32.8gb[14.8%], replicas will not be assigned to this node
[2016-04-14 14:48:16,963][INFO ][cluster.routing.allocation.decider] [Tower] rerouting shards: [one or more nodes has gone under the high or low watermark]
[2016-04-14 15:05:14,631][INFO ][node                     ] [Hera] version[2.3.1], pid[7294], build[bd98092/2016-04-04T12:25:05Z]
[2016-04-14 15:05:14,632][INFO ][node                     ] [Hera] initializing ...
[2016-04-14 15:05:15,892][INFO ][plugins                  ] [Hera] modules [lang-groovy, reindex, lang-expression], plugins [], sites []
[2016-04-14 15:05:16,018][INFO ][env                      ] [Hera] using [1] data paths, mounts [[/home/vagrant/Code (home_vagrant_Code)]], net usable_space [37.8gb], net total_space [221.5gb], spins? [possibly], types [vboxsf]
[2016-04-14 15:05:16,019][INFO ][env                      ] [Hera] heap size [1015.6mb], compressed ordinary object pointers [true]
[2016-04-14 15:05:16,020][WARN ][env                      ] [Hera] max file descriptors [4096] for elasticsearch process likely too low, consider increasing to at least [65536]
[2016-04-14 15:05:19,294][INFO ][node                     ] [Hera] initialized
[2016-04-14 15:05:19,295][INFO ][node                     ] [Hera] starting ...
[2016-04-14 15:05:19,382][INFO ][transport                ] [Hera] publish_address {127.0.0.1:9300}, bound_addresses {127.0.0.1:9300}, {[::1]:9300}
[2016-04-14 15:05:19,388][INFO ][discovery                ] [Hera] elasticsearch/igTQil5TQQeV8qR6vVZJsA
[2016-04-14 15:05:22,502][INFO ][cluster.service          ] [Hera] new_master {Hera}{igTQil5TQQeV8qR6vVZJsA}{127.0.0.1}{127.0.0.1:9300}, reason: zen-disco-join(elected_as_master, [0] joins received)
[2016-04-14 15:05:22,515][INFO ][http                     ] [Hera] publish_address {127.0.0.1:9200}, bound_addresses {127.0.0.1:9200}, {[::1]:9200}
[2016-04-14 15:05:22,516][INFO ][node                     ] [Hera] started
[2016-04-14 15:05:22,607][INFO ][gateway                  ] [Hera] recovered [0] indices into cluster_state
[2016-04-14 15:07:27,927][INFO ][cluster.metadata         ] [Hera] [homestead] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2016-04-14 15:07:29,239][INFO ][cluster.routing.allocation] [Hera] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[homestead][4]] ...]).
[2016-04-14 15:07:40,447][INFO ][cluster.metadata         ] [Hera] [homestead] creating index, cause [api], templates [], shards [5]/[1], mappings [vacancy, skill, volunteer, organisation, testimonial, contact]
[2016-04-14 15:07:41,073][INFO ][cluster.routing.allocation] [Hera] Cluster health status changed from [RED] to [YELLOW] (reason: [shards started [[homestead][4]] ...]).
[2016-04-14 19:08:49,143][INFO ][node                     ] [Hera] stopping ...
[2016-04-14 19:08:49,379][INFO ][node                     ] [Hera] stopped
[2016-04-14 19:08:49,380][INFO ][node                     ] [Hera] closing ...
[2016-04-14 19:08:49,398][INFO ][node                     ] [Hera] closed
